\subsection{Datengrundlage}
Als Datenquelle dient das Python-Paket FastF1 \parencite{fastf1_software}, das offizielle F1-Ergebnis- und
Qualifyingdaten bereitstellt. Pro Saison und Rennen werden Qualifying- und
Rennsessions geladen und pro Fahrer ein Datensatz erzeugt; jede Zeile entspricht
damit einem Fahrer in einem Grand Prix. Zwei Builder-Skripte erzeugen die
Features:
\begin{itemize}
  \item \textbf{Klassifikation (\texttt{build\_fastf1\_dataset.py}):} Verwendet
    ausschließlich vor dem Rennen verfügbare Informationen zur Vorhersage
    \texttt{points\_scored}. Merkmale: Fahrer-, Team- und Strecken-IDs
    (\texttt{driver\_id}, \sloppy \texttt{constructor\_id}, \texttt{circuit\_id}),
    Startposition (\texttt{grid\_position}), Qualifying-Deltas (gesamt und zum
    Teamkollegen: \texttt{quali\_delta}, \texttt{quali\_tm\_delta}),
    kumulierte Saisonpunkte (\texttt{season\_pts\_driver},
    \texttt{season\_pts\_team}), Punktemittelwert der letzten drei
    Rennen (\texttt{last\_3\_avg}) sowie Kontextflags für Stadtkurse und Regen
    (\texttt{is\_street\_circuit}, \texttt{is\_wet}).
  \item \textbf{Regression (\texttt{build\_fastf1\_dataset\_regression.py}):}
    Rekonstruiert konsistente Rennzeiten, indem die Siegerzeit als Referenz
    genutzt und Gaps addiert werden; DNFs bleiben als Status erkennbar.
    Zusätzliche Ziele: \texttt{gap\_to\_winner} (Sieger=0),
    \texttt{race\_time\_per\_lap} und Rundenanzahl (\texttt{laps}).
\end{itemize}
Um Generalisierung auf neue Fahrer/Teams/Strecken zu prüfen, werden unbekannte
Kategorien optional maskiert. Jahressplits verhindern, dass spätere Saisons in
die Trainingsphase leaken.
Die Ausfallquote pro Saison wurde mit dem Skript \sloppy \texttt{calc\_retirement\_rate.py}
aus den FastF1-Starts berechnet.

\subsection{Modellarchitekturen}
Die Daten sind tabellarisch mit einer Mischung aus kategorischen und
numerischen Merkmalen. Für beide Aufgaben (Klassifikation und Regression)
werden mehrere Modellfamilien verglichen:
\begin{itemize}
  \item \textbf{Lineare Baselines:} Logistische Regression (Klassifikation) bzw.
    lineare Modelle mit Regularisierung (Regression) als Vergleich.
  \item \textbf{Lineare Baseline:} Random Forests als robuste, nichtlineare Baseline \parencite{breiman_random_2001}.
  \item \textbf{Gradient Boosting:} XGBoost \parencite{chen_xgboost_2016} und
    LightGBM \parencite{ke_lightgbm_2017} für tabellarische
    Daten; effizient in Interaktionen und nichtlinearen Effekten.
  \item \textbf{Neuronale Netze:} Mehrschichtige Perzeptren mit Early Stopping, hauptsächlich für die Klassifikation erprobt.
  \item \textbf{TabPFN:} Vortrainiertes Few-Shot-Transformer-Modell
    \parencite{hollmann_tabpfn_2022}, das ohne Hyperparameter-Tuning
    konkurrenzfähige Performance liefern kann. TabPFN ist speziell für kleine
    bis mittlere tabellarische Datensätze ausgelegt; mit 3740 Trainingsbeispielen
    (insgesamt 4698 Zeilen) und 12 Merkmalen (4 kategorial, 8 numerisch) liegt
    der verwendete Datensatz im Zielbereich dieses Modells.
\end{itemize}

\subsection{Trainingssetup}
Die Datensätze werden nach Saison getrennt, um zeitliche Leckage zu vermeiden.
Typische Splits: Training bis einschließlich 2023, Validierung 2024, Test 2025
für Regression; für die Klassifikation wurden auch Saisons 2015--2025 in
Train/Val/Test mit 3740/479/479 Beispielen genutzt. Kategorische Variablen
werden je nach Modell One-Hot-kodiert oder als Integer-Indizes
verwendet. Numerische Merkmale werden imputiert (Median) und skaliert. Für
unausgewogene Klassen kommt in Baumverfahren eine balancierte Gewichtung zum
Einsatz. Allerdings hat sich gezeigt, dass die Klassenungleichheit bei der Klassifikation fast nicht existent ist, da durch die Punkteregelung fast die Hälfte der Fahrer Punkte erzielt.

Modellselektion erfolgt auf dem Validierungsset. Bei der Klassifikation wird
der Entscheidungsschwellenwert auf den Validierungs-\textit{F1}-Score optimiert
und anschließend auf dem Testset ausgewertet. Die Metriken die verwendet wurden: \textit{F1}
binär/makro und \textit{Balanced Accuracy}. In der Regression stehen
\textit{MAE}/\textit{RMSE} im Fokus; da ich zuerst davon ausgegangen wurde, dass sehr kleine Gaps prozentuale Kennzahlen aufblähen, wurde \textit{MAPE} nur ab 5\,s Gap sowie \textit{SMAPE} ergänzend angegeben. Allerdings hatte das keinen großen Einfluss auf \textit{MAPE}.

\subsection{Inferenz und UI}
Für die Klassifikationsaufgabe wurde ein leichtgewichtiges Inferenz-Setup ergänzt:
Das beste Modell (TabPFN) wird nach dem Fit inklusive der Kategoriekodierung
gespeichert und über einen kleinen API-Endpunkt bereitgestellt. Darauf aufbauend
wurde eine React-Anwendung mit Material UI umgesetzt, in der die Featurewerte
eingetragen werden können und die anschließend die vorhergesagte Klasse sowie
die zugehörige Wahrscheinlichkeit ausgibt. Die Oberfläche dient als praktische
Demonstration, wie das trainierte Modell mit den im Notebook definierten
Features (Fahrer, Team, Strecke, Jahr und numerische Kontextmerkmale) in eine
bedienbare Anwendung überführt werden kann. Die Anwendung kann unter folgender Adresse getestet werden: \url{https://dl.devoniq.de/}. Da dies ein Server ist, der primär für andere Zwecke genutzt wird, kann es für eine Vorhersage bis zu 5min dauern.
