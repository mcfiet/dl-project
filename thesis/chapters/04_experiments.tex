\subsection{Klassifikation: Punktevorhersage}
Die Notebook-Serie \texttt{notebooks/points\_scored/} dokumentiert die
Experimentreihen zur Klassifikation und folgt den in Abschnitt
\textit{Modellarchitekturen} beschriebenen Familien: lineare Baselines, baumbasierte
Verfahren (Random Forest, XGBoost), ein MLP sowie TabPFN. Die Umsetzung liegt in
\texttt{baseline\_training.ipynb},
\sloppy \texttt{random\_forest\_baseline.ipynb},
\texttt{xgboost\_training.ipynb}, \texttt{model\_training.ipynb} und
\texttt{tabpfn.ipynb}; ergänzend analysiert
\texttt{learning\_curve\_analysis.ipynb} die Abhängigkeit von der Trainingsgröße.

Im Laufe der Experimente wurden außerdem verschiedene Feature-Engineering-Ansätze mit dem TabPFN getestet.
Dazu zählten Versuche mit potenziell ``leckenden'' Merkmalen wie \texttt{avg\_racetime}, die später wieder entfernt wurden,
sowie Variationen im Encoding (One-Hot, Integer-Indizes, Target Encoding) und das Maskieren unbekannter Kategorien.

Die Analyse zeigt deutlich, dass die Startposition (\texttt{grid\_position}) der wichtigste Faktor für die Vorhersage ist: Je weiter vorne ein Fahrer startet, desto wahrscheinlicher erzielt er Punkte. Als zweitwichtigste Indikatoren identifiziert das TabPFN-Modell die aktuelle Form (\texttt{last\_3\_avg}) und die Saisonleistung des Teams (\texttt{season\_pts\_team}).

Auffällig ist, dass die Team-Punkte wichtiger eingestuft werden als die Punkte des Fahrers. Da beide Werte extrem stark zusammenhängen (Korrelation von $0.96$), hat das Modell gelernt bevorzugt die Team-Daten zu nehmen. Reine Identifikationsmerkmale wie die \texttt{constructor\_id} liefern keinen Mehrwert und wirken sich sogar leicht negativ auf die Vorhersagequalität aus.

\vspace{1cm}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/tabpfn_feature_importance.png}
  \caption{Feature Importance des TabPFN-Modells für die Klassifikationsaufgabe (Punktevorhersage).}
\end{figure}
\vspace{1cm}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/tabpfn_feature_heatmap.png}
  \caption{Feature Heatmap des TabPFN-Modells für die Klassifikationsaufgabe (Punktevorhersage).}
\end{figure}
\subsection{Regression: Rennzeit und Gap zum Sieger}
Die Notebook-Serie \texttt{notebooks/regression/} dokumentiert die Entwicklung
des Regressionsziels von der absoluten Rennzeit hin zum robusteren
\texttt{gap\_to\_winner} und nutzt dabei die in Abschnitt \textit{Modellarchitekturen}
beschriebenen Familien (Gradient Boosting/LightGBM, Random Forest, TabPFN sowie
lineare Baselines). Die konkreten Experimente liegen in
\texttt{baseline\_regression.ipynb}, \texttt{gap\_to\_winner\_regression.ipynb},
\texttt{random\_forest\_regression.ipynb} und \texttt{tabpfn\_regression.ipynb}.
Die Entwicklung umfasste zudem Tests mit Log-Transformationen und Normalisierungen der absoluten Zeit,
welche jedoch keine signifikante Verbesserung brachten. Der Daten-Builder wurde daraufhin angepasst, um konsistente
Rennzeiten (Siegerzeit + Gap) zu generieren und relevante Metriken wie \texttt{race\_status},
\texttt{laps}, \texttt{gap\_to\_winner} und \texttt{race\_time\_per\_lap} zu speichern.

Als neueste Erweiterung wurde ein separater Datensatz mit Trainingssessions (FP1--FP3) ergänzt
(\texttt{data/regression/with\_training\_sessions/}). Dieser erweitert das Feature-Set um
Bestzeiten, relative Abstände zur Session-Bestzeit und Rundenanzahlen
(\texttt{fp1\_best}, \texttt{fp2\_best}, \texttt{fp3\_best},
\texttt{fp1\_rel}--\texttt{fp3\_rel}, \texttt{fp1\_laps}--\texttt{fp3\_laps}).
Die zugehörigen Experimente liegen in \texttt{notebooks/regression/with\_training\_sessions/}
und replizieren die Baselines (LGBM, RF, XGBoost, TabPFN) mit dem erweiterten
Feature-Set.
