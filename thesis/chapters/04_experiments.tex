\subsection{Regression: Rennzeit und Gap zum Sieger}
Zu Beginn wurde versucht, die absolute Rennzeit auf Basis der bekannten Features (Fahrer/Team/Strecke, Grid, Quali-Deltas, Saisonpunkte, Rolling-Average, Street-/Wet-Flags) in einer Regression abzubilden. Die Fehler lagen jedoch hoch (MAE rund 0{,}6--0{,}9\,ks, RMSE über 1\,ks), weil FastF1 im Ergebnis \emph{entweder} die Siegerzeit \emph{oder} den Gap zur Spitze liefert und DNFs/fehlende Zeiten gemischt auftreten. Daraufhin wurde das Datenerzeugungsskript angepasst: \texttt{build\_fastf1\_dataset\_regression.py} rekonstruiert nun konsistente Rennzeiten (Siegerzeit als Referenz, andere Fahrer via Gap addiert) und speichert zusätzlich \texttt{race\_status}, \texttt{laps}, \texttt{gap\_to\_winner} und \texttt{race\_time\_per\_lap}; extreme Ausreißer werden per 1--99\,\%-Quantil gekappt.

Log- und Normalisierungsansätze auf der absoluten Zeit (inklusive per-Runde- und Jahr-Median-Normierung) senkten zwar die MAPE, änderten aber wenig am hohen MAE/RMSE, weil Safety-Car-Phasen, rote Flaggen und Renndistanz das Ziel dominieren. Daher wurde das Target auf \texttt{gap\_to\_winner} (Sieger=0) umgestellt und mit \texttt{log1p} transformiert. Ein LightGBMRegressor mit dem bisherigen Feature-Set plus \texttt{laps} erzielte damit Val MAE von etwa 26\,s (RMSE ca. 33\,s) und Test MAE von etwa 23\,s (RMSE ca. 30\,s) bei Splits Train $\leq$2022, Val 2023, Test 2024. Prozentmetriken explodieren wegen sehr kleiner Gaps; deshalb wird MAPE nur für Gaps ab 5\,s berichtet und zusätzlich SMAPE genutzt, während MAE/RMSE die Hauptbewertung bleiben.

Offen bleiben weitere Schritte: ein per-Runde-Gap/Pace-Target mit Rückrechnung auf die Gesamtrennzeit, zusätzliche Kontext-Features (Safety-Car/Virtual-Safety-Car-Runden, Boxenstopps, Renndistanz) sowie Modell-Tuning (LightGBM/XGBoost) und alternative Zieldefinitionen.

\subsection{Zusammenfassung}
