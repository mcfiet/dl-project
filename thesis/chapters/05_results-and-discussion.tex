\subsection{Ergebnisse und Diskussion}
Die Ergebnisse der durchgeführten Experimente werden in diesem Abschnitt vorgestellt und diskutiert.
Die zentralen Metriken der getesteten Modelle sind in den Tabellen \ref{tab:classification_results} und \ref{tab:regression_results} zusammengefasst.

\subsubsection{Klassifikation (Points Scored)}
Für die Klassifikationsaufgabe, die Vorhersage, ob ein Fahrer Punkte erzielt, wurden mehrere Modelle verglichen.
Die Ergebnisse auf dem Testset sind in Tabelle \ref{tab:classification_results} dargestellt.

\begin{table}[H]
\centering

\label{tab:classification_results}
\begin{tabular}{lrrr}
\toprule
\textbf{Modell} & \textbf{F1-Score (binär)} & \textbf{Accuracy} & \textbf{Balanced Accuracy} \\
\midrule
TabPFN & $\approx 0,855$ & $\approx 0,850$ & $\approx 0,850$ \\
Random Forest & $\approx 0,835$ & $\approx 0,829$ & $\approx 0,829$ \\
XGBoost & $\approx 0,763$ & $\approx 0,747$ & $\approx 0,747$ \\
Neuronales Netz & $\approx 0,746$ & $\approx 0,733$ & $\approx 0,733$ \\
Baseline (Logit/XGB) & $\approx 0,82$ & $\approx 0,82$ & $\approx 0,82$ \\
\bottomrule
\end{tabular}
\caption{Ergebnisse der Klassifikationsmodelle zur Vorhersage von Punkterfolgen (Testset).}
\end{table}

\subsubsection{Regression (Gap-to-Winner)}
Für die Regressionsaufgabe wurde der Abstand zum Sieger (\texttt{gap\_to\_winner}) als Zielgröße modelliert.
Tabelle \ref{tab:regression_results} zeigt die wichtigsten Fehlermetriken auf dem Testset.
Die ursprüngliche Modellierung der absoluten Rennzeit erwies sich mit einem MAE von über 600\,s als ungeeignet, weshalb diese Ergebnisse hier nicht weiter aufgeführt werden.

\begin{table}[H]
\centering
\label{tab:regression_results}
\begin{tabular}{lrr}
\toprule
\textbf{Modell} & \textbf{MAE} & \textbf{RMSE} \\
\midrule
Random Forest & 21,8\,s & 28,0\,s \\
TabPFN & 22,7\,s & 28,9\,s \\
LightGBM & 23,2\,s & 30,1\,s \\
\bottomrule
\end{tabular}
\caption{Ergebnisse der Regressionsmodelle zur Vorhersage des \textnormal{gap\_to\_winner} (Testset).}
\end{table}

\textbf{Interpretation.}
Wie Tabelle \ref{tab:classification_results} zeigt, erzielt das vortrainierte TabPFN-Modell die besten Ergebnisse für die Klassifikation. Dicht gefolgt wird es vom Random Forest, was die Stärke von baumbasierten Modellen für diese Art von tabellarischen Daten unterstreicht. XGBoost und das einfache neuronale Netz können auf dem Testset nicht mithalten.

In der Regression (siehe Tabelle~\ref{tab:regression_results}) liefert der Random Forest den niedrigsten MAE, knapp vor TabPFN und LightGBM. Der Wechsel des Ziels von der absoluten Rennzeit auf den \texttt{gap\_to\_winner} hat die Varianz der Zielgröße signifikant reduziert und aussagekräftige Vorhersagen ermöglicht. Die verbleibenden Fehler sind vermutlich auf nicht modellierte Rennkontext-Features (z.\,B.\ Safety-Car-Phasen, Boxenstopps) zurückzuführen. Prozentuale Metriken wie SMAPE reagieren bei sehr kleinen Gaps überproportional, weshalb MAE und RMSE die primären Bewertungsmetriken bleiben.

Wichtig für die Validität der Ergebnisse ist die strikte, jahresbasierte Trennung der Daten, um eine Datenleckage durch Informationen aus der Zukunft zu vermeiden.

\subsection{Limitationen.}
\begin{itemize}
    \item Relativ kleine Trainingsmengen pro Saison
    \item Keine explizite Modellierung von DNFs/Safety-Car/Boxenstopps
    \item TabPFN ohne systematische Tuning-Studie
\end{itemize}

Diese Punkte begrenzen derzeit die Generalisierung auf neue Saisons.
