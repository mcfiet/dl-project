{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122203e5",
   "metadata": {},
   "source": [
    "# First Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4814b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2094ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATA_PATH = 'data/grandprix_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5aefa569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  round               event driver          team  quali_position  \\\n",
      "0  2022      1  Bahrain Grand Prix    LEC       Ferrari               1   \n",
      "1  2022      1  Bahrain Grand Prix    SAI       Ferrari               3   \n",
      "2  2022      1  Bahrain Grand Prix    HAM      Mercedes               5   \n",
      "3  2022      1  Bahrain Grand Prix    RUS      Mercedes               9   \n",
      "4  2022      1  Bahrain Grand Prix    MAG  Haas F1 Team               7   \n",
      "\n",
      "   avg_race_lap_time_s  finish_position  points_awarded  prev_points_total  \\\n",
      "0            97.604208              1.0            26.0                0.0   \n",
      "1            98.079957              2.0            18.0                0.0   \n",
      "2            98.266244              3.0            15.0                0.0   \n",
      "3            98.639022              4.0            12.0                0.0   \n",
      "4            98.852833              5.0            10.0                0.0   \n",
      "\n",
      "   scored_points  \n",
      "0              1  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              1  \n",
      "year                     int64\n",
      "round                    int64\n",
      "event                   object\n",
      "driver                  object\n",
      "team                    object\n",
      "quali_position           int64\n",
      "avg_race_lap_time_s    float64\n",
      "finish_position        float64\n",
      "points_awarded         float64\n",
      "prev_points_total      float64\n",
      "scored_points            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36793a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  round               event driver      team  quali_position  \\\n",
      "0  2022      1  Bahrain Grand Prix    LEC   Ferrari               1   \n",
      "1  2022      1  Bahrain Grand Prix    SAI   Ferrari               3   \n",
      "2  2022      1  Bahrain Grand Prix    HAM  Mercedes               5   \n",
      "\n",
      "   avg_race_lap_time_s  finish_position  points_awarded  prev_points_total  \\\n",
      "0            97.604208              1.0            26.0                0.0   \n",
      "1            98.079957              2.0            18.0                0.0   \n",
      "2            98.266244              3.0            15.0                0.0   \n",
      "\n",
      "   scored_points  \n",
      "0              1  \n",
      "1              1  \n",
      "2              1  \n",
      "Driver value counts:\n",
      "driver\n",
      "LEC    68\n",
      "HAM    68\n",
      "RUS    68\n",
      "BOT    68\n",
      "STR    68\n",
      "TSU    68\n",
      "ZHO    68\n",
      "ALO    68\n",
      "PER    68\n",
      "VER    68\n",
      "GAS    68\n",
      "NOR    68\n",
      "ALB    67\n",
      "SAI    67\n",
      "OCO    67\n",
      "MAG    66\n",
      "HUL    48\n",
      "RIC    47\n",
      "PIA    46\n",
      "SAR    36\n",
      "MSC    22\n",
      "LAT    22\n",
      "VET    20\n",
      "DEV    11\n",
      "LAW    11\n",
      "COL     9\n",
      "BEA     3\n",
      "DOO     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Datenverteilung untersuchen\n",
    "def inspect_csv(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    print(df.head(3))\n",
    "    print(\"Driver value counts:\")\n",
    "    print(df[\"driver\"].value_counts())\n",
    "\n",
    "inspect_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a17c22f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drivers: {'ALB': 0, 'ALO': 1, 'BEA': 2, 'BOT': 3, 'COL': 4, 'DEV': 5, 'DOO': 6, 'GAS': 7, 'HAM': 8, 'HUL': 9, 'LAT': 10, 'LAW': 11, 'LEC': 12, 'MAG': 13, 'MSC': 14, 'NOR': 15, 'OCO': 16, 'PER': 17, 'PIA': 18, 'RIC': 19, 'RUS': 20, 'SAI': 21, 'SAR': 22, 'STR': 23, 'TSU': 24, 'VER': 25, 'VET': 26, 'ZHO': 27}\n",
      "Teams: {'Alfa Romeo': 0, 'AlphaTauri': 1, 'Alpine': 2, 'Aston Martin': 3, 'Ferrari': 4, 'Haas F1 Team': 5, 'Kick Sauber': 6, 'McLaren': 7, 'Mercedes': 8, 'RB': 9, 'Red Bull Racing': 10, 'Williams': 11}\n",
      "Events: {'Abu Dhabi Grand Prix': 0, 'Australian Grand Prix': 1, 'Austrian Grand Prix': 2, 'Azerbaijan Grand Prix': 3, 'Bahrain Grand Prix': 4, 'Belgian Grand Prix': 5, 'British Grand Prix': 6, 'Canadian Grand Prix': 7, 'Chinese Grand Prix': 8, 'Dutch Grand Prix': 9, 'Emilia Romagna Grand Prix': 10, 'French Grand Prix': 11, 'Hungarian Grand Prix': 12, 'Italian Grand Prix': 13, 'Japanese Grand Prix': 14, 'Las Vegas Grand Prix': 15, 'Mexico City Grand Prix': 16, 'Miami Grand Prix': 17, 'Monaco Grand Prix': 18, 'Qatar Grand Prix': 19, 'Saudi Arabian Grand Prix': 20, 'Singapore Grand Prix': 21, 'Spanish Grand Prix': 22, 'SÃ£o Paulo Grand Prix': 23, 'United States Grand Prix': 24}\n"
     ]
    }
   ],
   "source": [
    "# Fahrer, Teams, Events in Indizes umwandeln\n",
    "drivers = sorted(df[\"driver\"].unique())\n",
    "teams = sorted(df[\"team\"].unique())\n",
    "events = sorted(df[\"event\"].unique())\n",
    "\n",
    "driver_to_idx = {d: i for i, d in enumerate(drivers)}\n",
    "team_to_idx   = {t: i for i, t in enumerate(teams)}\n",
    "event_to_idx  = {e: i for i, e in enumerate(events)}\n",
    "\n",
    "# Umkehrung der Mappings\n",
    "idx_to_driver = {idx: drv for drv, idx in driver_to_idx.items()}\n",
    "idx_to_team   = {idx: tm for tm, idx in team_to_idx.items()}\n",
    "idx_to_event  = {idx: ev for ev, idx in event_to_idx.items()}\n",
    "\n",
    "print(f\"Drivers: {driver_to_idx}\")\n",
    "print(f\"Teams: {team_to_idx}\")\n",
    "print(f\"Events: {event_to_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7917dd",
   "metadata": {},
   "source": [
    "## Dataset Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "378202ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrandPrixDataset(Dataset):\n",
    "    def __init__(self, csv_path: str):\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        self.drivers = sorted(df[\"driver\"].unique())\n",
    "        self.teams = sorted(df[\"team\"].unique())\n",
    "        self.events = sorted(df[\"event\"].unique())\n",
    "\n",
    "        self.driver_to_idx = {d: i for i, d in enumerate(self.drivers)}\n",
    "        self.team_to_idx   = {t: i for i, t in enumerate(self.teams)}\n",
    "        self.event_to_idx  = {e: i for i, e in enumerate(self.events)}\n",
    "\n",
    "        # convert to tensors\n",
    "        self.years = torch.tensor(df[\"year\"].values, dtype=torch.int64)\n",
    "        self.rounds = torch.tensor(df[\"round\"].values, dtype=torch.int64)\n",
    "        self.quali_positions = torch.tensor(df[\"quali_position\"].values, dtype=torch.int64)\n",
    "        self.avg_lap_times = torch.tensor(df[\"avg_race_lap_time_s\"].values, dtype=torch.float32)\n",
    "        self.prev_points = torch.tensor(df[\"prev_points_total\"].values, dtype=torch.float32)\n",
    "\n",
    "        driver_ids = df[\"driver\"].map(self.driver_to_idx).values\n",
    "        team_ids = df[\"team\"].map(self.team_to_idx).values\n",
    "        event_ids = df[\"event\"].map(self.event_to_idx).values\n",
    "\n",
    "        self.driver_ids = torch.tensor(driver_ids, dtype=torch.int64)\n",
    "        self.team_ids = torch.tensor(team_ids, dtype=torch.int64)\n",
    "        self.event_ids = torch.tensor(event_ids, dtype=torch.int64)\n",
    "\n",
    "        self.targets = torch.tensor(df[\"scored_points\"].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        numeric_features = torch.tensor([\n",
    "            self.years[idx],\n",
    "            self.rounds[idx],\n",
    "            self.quali_positions[idx],\n",
    "        ], dtype=torch.float32)     \n",
    "\n",
    "        categorical_features = torch.tensor([\n",
    "            self.driver_ids[idx],\n",
    "            self.team_ids[idx],\n",
    "            self.event_ids[idx],\n",
    "        ], dtype=torch.int64)\n",
    "\n",
    "        x = {\n",
    "            \"numeric\": numeric_features,\n",
    "            \"categorical\": categorical_features,\n",
    "        }\n",
    "\n",
    "        y = self.targets[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd47ad6",
   "metadata": {},
   "source": [
    "## Train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28ecc892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815 271 273\n"
     ]
    }
   ],
   "source": [
    "dataset = GrandPrixDataset(DATA_PATH)\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "\n",
    "train_ds, val_ds, test_ds = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size],\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "print(len(train_ds), len(val_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "335996a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader erstellen\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e83968ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric shape: torch.Size([32, 3])\n",
      "categorical shape: torch.Size([32, 3])\n",
      "targets shape: torch.Size([32])\n",
      "numeric example: tensor([2023.,   17.,   20.])\n",
      "categorical example: tensor([27,  0, 19])\n",
      "target example: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Batch anschauen\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"numeric shape:\", x_batch[\"numeric\"].shape)\n",
    "print(\"categorical shape:\", x_batch[\"categorical\"].shape)\n",
    "print(\"targets shape:\", y_batch.shape)\n",
    "\n",
    "print(\"numeric example:\", x_batch[\"numeric\"][0])\n",
    "print(\"categorical example:\", x_batch[\"categorical\"][0])\n",
    "print(\"target example:\", y_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78134e2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1726e73c",
   "metadata": {},
   "source": [
    "### Model Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "642f8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NUMERIC_FEATURES = 3\n",
    "\n",
    "NUM_CATEGORICAL_FEATURES = 3\n",
    "\n",
    "class SimplePointsMLP(nn.Module):\n",
    "    def __init__(self, num_numeric_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(num_numeric_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        numeric = x[\"numeric\"].float()\n",
    "        return self.net(numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063264a",
   "metadata": {},
   "source": [
    "### Modell & Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59c0cb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Modell\n",
    "model = SimplePointsMLP(NUM_NUMERIC_FEATURES).to(device)\n",
    "\n",
    "# Loss und Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3aecc",
   "metadata": {},
   "source": [
    "### Trainingsloop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdac91a",
   "metadata": {},
   "source": [
    "#### Train und evaluate in Funktionen ausgelagert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "393a1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch = {k: v.to(device) for k, v in x_batch.items()}\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        y_batch = y_batch.unsqueeze(1)\n",
    "\n",
    "        logits = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y_batch.size(0)\n",
    "        total_samples += y_batch.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            total_correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = {k: v.to(device) for k, v in x_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            y_batch = y_batch.unsqueeze(1)\n",
    "\n",
    "            logits = model(x_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "\n",
    "            total_loss += loss.item() * y_batch.size(0)\n",
    "            total_samples += y_batch.size(0)\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            total_correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310a76d",
   "metadata": {},
   "source": [
    "#### Trainingsloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2c89dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 4.8155  Acc: 0.502 | Val Loss: 0.8992  Acc: 0.469\n",
      "Epoch 02 | Train Loss: 1.0245  Acc: 0.517 | Val Loss: 0.7839  Acc: 0.469\n",
      "Epoch 02 | Train Loss: 1.0245  Acc: 0.517 | Val Loss: 0.7839  Acc: 0.469\n",
      "Epoch 03 | Train Loss: 0.7655  Acc: 0.528 | Val Loss: 0.8394  Acc: 0.469\n",
      "Epoch 03 | Train Loss: 0.7655  Acc: 0.528 | Val Loss: 0.8394  Acc: 0.469\n",
      "Epoch 04 | Train Loss: 0.7173  Acc: 0.556 | Val Loss: 0.9003  Acc: 0.469\n",
      "Epoch 04 | Train Loss: 0.7173  Acc: 0.556 | Val Loss: 0.9003  Acc: 0.469\n",
      "Epoch 05 | Train Loss: 0.7244  Acc: 0.569 | Val Loss: 0.6182  Acc: 0.694\n",
      "Epoch 05 | Train Loss: 0.7244  Acc: 0.569 | Val Loss: 0.6182  Acc: 0.694\n",
      "Epoch 06 | Train Loss: 0.6765  Acc: 0.572 | Val Loss: 0.7511  Acc: 0.531\n",
      "Epoch 06 | Train Loss: 0.6765  Acc: 0.572 | Val Loss: 0.7511  Acc: 0.531\n",
      "Epoch 07 | Train Loss: 0.7433  Acc: 0.542 | Val Loss: 0.8060  Acc: 0.469\n",
      "Epoch 08 | Train Loss: 0.6532  Acc: 0.607 | Val Loss: 0.6332  Acc: 0.572\n",
      "Epoch 07 | Train Loss: 0.7433  Acc: 0.542 | Val Loss: 0.8060  Acc: 0.469\n",
      "Epoch 08 | Train Loss: 0.6532  Acc: 0.607 | Val Loss: 0.6332  Acc: 0.572\n",
      "Epoch 09 | Train Loss: 0.8424  Acc: 0.545 | Val Loss: 0.7751  Acc: 0.531\n",
      "Epoch 09 | Train Loss: 0.8424  Acc: 0.545 | Val Loss: 0.7751  Acc: 0.531\n",
      "Epoch 10 | Train Loss: 0.8234  Acc: 0.560 | Val Loss: 0.7015  Acc: 0.531\n",
      "Epoch 10 | Train Loss: 0.8234  Acc: 0.560 | Val Loss: 0.7015  Acc: 0.531\n",
      "Epoch 11 | Train Loss: 0.7864  Acc: 0.555 | Val Loss: 1.2220  Acc: 0.469\n",
      "Epoch 12 | Train Loss: 0.7567  Acc: 0.567 | Val Loss: 1.0185  Acc: 0.531\n",
      "Epoch 11 | Train Loss: 0.7864  Acc: 0.555 | Val Loss: 1.2220  Acc: 0.469\n",
      "Epoch 12 | Train Loss: 0.7567  Acc: 0.567 | Val Loss: 1.0185  Acc: 0.531\n",
      "Epoch 13 | Train Loss: 1.0542  Acc: 0.519 | Val Loss: 1.7382  Acc: 0.531\n",
      "Epoch 13 | Train Loss: 1.0542  Acc: 0.519 | Val Loss: 1.7382  Acc: 0.531\n",
      "Epoch 14 | Train Loss: 0.8181  Acc: 0.579 | Val Loss: 0.5445  Acc: 0.731\n",
      "Epoch 14 | Train Loss: 0.8181  Acc: 0.579 | Val Loss: 0.5445  Acc: 0.731\n",
      "Epoch 15 | Train Loss: 0.6096  Acc: 0.667 | Val Loss: 0.6778  Acc: 0.524\n",
      "Epoch 16 | Train Loss: 0.6716  Acc: 0.616 | Val Loss: 0.5617  Acc: 0.742\n",
      "Epoch 15 | Train Loss: 0.6096  Acc: 0.667 | Val Loss: 0.6778  Acc: 0.524\n",
      "Epoch 16 | Train Loss: 0.6716  Acc: 0.616 | Val Loss: 0.5617  Acc: 0.742\n",
      "Epoch 17 | Train Loss: 0.5874  Acc: 0.692 | Val Loss: 0.6642  Acc: 0.542\n",
      "Epoch 17 | Train Loss: 0.5874  Acc: 0.692 | Val Loss: 0.6642  Acc: 0.542\n",
      "Epoch 18 | Train Loss: 0.5977  Acc: 0.676 | Val Loss: 0.7728  Acc: 0.531\n",
      "Epoch 18 | Train Loss: 0.5977  Acc: 0.676 | Val Loss: 0.7728  Acc: 0.531\n",
      "Epoch 19 | Train Loss: 0.6251  Acc: 0.675 | Val Loss: 0.6171  Acc: 0.594\n",
      "Epoch 20 | Train Loss: 0.6671  Acc: 0.617 | Val Loss: 0.5118  Acc: 0.801\n",
      "Epoch 19 | Train Loss: 0.6251  Acc: 0.675 | Val Loss: 0.6171  Acc: 0.594\n",
      "Epoch 20 | Train Loss: 0.6671  Acc: 0.617 | Val Loss: 0.5118  Acc: 0.801\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f}  Acc: {train_acc:.3f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}  Acc: {val_acc:.3f}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
