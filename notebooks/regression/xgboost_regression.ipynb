{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGBoost-Regression: Rennzeit\n",
        "\n",
        "Hinweis: ben√∂tigt `xgboost` installiert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "DATA_PATH = Path(\"data/regression/grandprix_features_all.csv\")\n",
        "CAT_COLS = ['driver_id', 'constructor_id', 'circuit_id']\n",
        "NUM_COLS = ['year', 'round_number', 'grid_position', 'quali_delta', 'quali_tm_delta', 'season_pts_driver', 'season_pts_team', 'last_3_avg', 'is_street_circuit', 'is_wet']\n",
        "TARGET = \"race_time\"\n",
        "\n",
        "df = pd.read_csv(DATA_PATH).dropna(subset=[TARGET]).copy()\n",
        "train_df = df[df[\"year\"] <= 2022]\n",
        "val_df = df[df[\"year\"] == 2023]\n",
        "test_df = df[df[\"year\"] == 2024]\n",
        "\n",
        "X_train, y_train = train_df[CAT_COLS + NUM_COLS], train_df[TARGET]\n",
        "X_val, y_val = val_df[CAT_COLS + NUM_COLS], val_df[TARGET]\n",
        "X_test, y_test = test_df[CAT_COLS + NUM_COLS], test_df[TARGET]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_COLS),\n",
        "    (\n",
        "        \"num\",\n",
        "        Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", StandardScaler()),\n",
        "        ]),\n",
        "        NUM_COLS,\n",
        "    ),\n",
        "])\n",
        "\n",
        "xgb = XGBRegressor(\n",
        "    objective=\"reg:squarederror\",\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=1200,\n",
        "    max_depth=8,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    min_child_weight=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"model\", xgb),\n",
        "])\n",
        "\n",
        "pipe.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    model__eval_set=[(preprocess.transform(X_val), y_val)],\n",
        "    model__verbose=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for split, X, y in [(\"val\", X_val, y_val), (\"test\", X_test, y_test)]:\n",
        "    preds = pipe.predict(X)\n",
        "    mae = mean_absolute_error(y, preds)\n",
        "    rmse = sqrt(mean_squared_error(y, preds))\n",
        "    mape = (np.abs((y - preds) / y).replace([np.inf, -np.inf], np.nan)).median() * 100\n",
        "    print(f\"{split}: MAE={mae:.2f}s RMSE={rmse:.2f}s MAPE~{mape:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
